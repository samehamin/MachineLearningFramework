{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this lesson, various algorithm evaluation metrics are demonstrated for both classification and regression type machine learning problems\n",
    "     - For classification metrics, the Pima Indians onset of diabetes dataset is used as demon- stration. This is a binary classification problem where all of the input variables are numeric.\n",
    "     - For regression metrics, the Boston House Price dataset is used as demonstration. this is a regression problem where all of the input variables are also numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Accuracy. \n",
    "- Logarithmic Loss.\n",
    "- Area Under ROC Curve. \n",
    "- Confusion Matrix.\n",
    "- Classification Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy\n",
    "- Classification accuracy is the number of correct predictions made as a ratio of all predictions made.\n",
    "- It is really only suitable when there are an equal number of observations in each class, which is rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "filename = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \n",
    "dataframe = read_csv(filename, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarithmic Loss\n",
    "- Evaluating the predictions of probabilities of membership to a given class.\n",
    "- The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm.\n",
    "- Predictions that are correct or incorrect are rewarded or punished proportionally to the confidence of the prediction.\n",
    "- Smaller logloss is better with 0 representing a perfect logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.493 (0.047)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under ROC Curve\n",
    "- Performance metric for binary classification problems.\n",
    "- Ability to discriminate between positive and negative classes.\n",
    "- An area of 1.0 represents a model that made all predictions perfectly.\n",
    "- An area of 0.5 represents a model that is as good as random.\n",
    "- A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "    - Sensitivity is the true positive rate also called the recall. It is the number of instances from the positive (first) class that actually predicted correctly.\n",
    "    - Specificity is also called the true negative rate. Is the number of instances from the\n",
    "negative (second) class that were actually predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "- A table of cells, where each cell represent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "    random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of the confusion matrix (suppose we're doing binary classifying Yes/No)\n",
    "    - How many Actual No and Predicted No\n",
    "    - How many Actual Yes and Predicted Yes\n",
    "    - How many Actual No and Predicted Yes\n",
    "    - How many Actual Yes and Predicted No\n",
    "<br/> <img alt=\"\" src=\"images/confmat.png\" width=\"500px\" height=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "- The classification report() function displays the precision, recall, F1-score and support for each class\n",
    "- The example below demonstrates the report on the binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.87      0.82       162\n",
      "         1.0       0.71      0.55      0.62        92\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       254\n",
      "   macro avg       0.74      0.71      0.72       254\n",
      "weighted avg       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "    random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/metrics.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision means the percentage of your results which are relevant\n",
    "- Recall refers to the percentage of total relevant results correctly classified by your algorithm\n",
    "- Full description of those measure\n",
    "https://towardsdatascience.com/precision-vs-recall-386cf9f89488\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"images/f1-score.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1 Score: The harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean Absolute Error\n",
    "- Mean Squared Error \n",
    "- R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error\n",
    "- The sum of the absolute differences between predictions and actual values\n",
    "- how wrong the predictions were and the magnitude of the error, but no idea of the direction\n",
    "- A value of 0 indicates no error or perfect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.005 (2.084)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MAE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', \n",
    "         'B', 'LSTAT', 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "- Provides a gross idea of the magnitude of error\n",
    "- Taking the square root of the mean squared error\n",
    "- This is called the Root Mean Squared Error (or RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -34.705 (45.574)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Metric\n",
    "- An indication of the goodness of fit of a set of predictions to the actual values\n",
    "- This is called the coefficient of determination\n",
    "- This is a value between 0 and 1 for no-fit and perfect fit respectively\n",
    "- You can see the predictions have a poor fit to the actual values with a value closer to zero and less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.203 (0.595)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
